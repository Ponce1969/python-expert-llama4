# ğŸ¤– Python Expert LLaMA-4

Una aplicaciÃ³n de lÃ­nea de comandos especializada en Python que aprovecha el modelo LLaMA-4 Scout a travÃ©s de la API de Groq. DiseÃ±ada especÃ­ficamente para desarrolladores de Python, ofrece asistencia en cÃ³digo, buenas prÃ¡cticas y resoluciÃ³n de problemas con capacidades de streaming optimizado, historial de chat persistente y exportaciÃ³n de conversaciones.

## ğŸ“ CaracterÃ­sticas

- **Asistente Experto en Python con LLaMA-4 Scout**
  - Especializado en cÃ³digo, patrones y buenas prÃ¡cticas de Python
  - Respuestas prÃ¡cticas con ejemplos de cÃ³digo funcional
  - Ventana de contexto extendida de 131,072 tokens
  - Respuestas de hasta 8,192 tokens
  - Temperatura configurable (0.0-1.0) para balancear precisiÃ³n y creatividad

- **Interfaz CLI intuitiva** 
  - DiseÃ±o visual con Rich para una experiencia mejorada
  - Comandos intuitivos con explicaciones claras
  - Indicadores visuales de progreso durante la generaciÃ³n

- **Streaming optimizado y visual mejorado** 
  - Respuestas en tiempo real sin saturaciÃ³n de memoria
  - VisualizaciÃ³n de tokens generados progresivamente
  - Respuestas completas y limpias en panel visual (Rich), sin cortes ni mensajes de estado mezclados
  - Experiencia de usuario mucho mÃ¡s fluida y profesional

- **Historial persistente avanzado** 
  - Almacenamiento en PostgreSQL para conversaciones duraderas
  - Sistema de separaciÃ³n de contextos que evita contaminaciÃ³n entre sesiones
  - Manejo de contexto optimizado con filtrado multi-capa
  - PreservaciÃ³n de la estructura conversacional limpia

- **ExportaciÃ³n profesional** 
  - Formatos Markdown y PDF con diseÃ±o profesional
  - OrganizaciÃ³n clara de mensajes con timestamps
  - ExportaciÃ³n simple con comandos directos `/export`

- **Docker Ready** 
  - Despliegue completo con docker-compose
  - Base de datos PostgreSQL incluida
  - ConfiguraciÃ³n centralizada en archivo `.env`

## ğŸ†• Mejoras recientes

- Las respuestas del asistente ahora se muestran en un **panel visual profesional** usando [Rich](https://rich.readthedocs.io/), con tÃ­tulo y borde destacado.
- Se eliminaron los mensajes de estado y cortes intermedios: la respuesta es continua, clara y sin interrupciones.
- El sistema aprovecha la ventana de tokens extendida del modelo LLaMA-4 Scout.
- Mejor experiencia visual y de lectura para el usuario.

## ğŸ› ï¸ Requisitos

- Python 3.9-3.12
- API Key de Groq (obtÃ©n una en [console.groq.com](https://console.groq.com))

## ğŸš€ InstalaciÃ³n

### InstalaciÃ³n con Docker (recomendada)

1. Clona este repositorio:
   ```bash
   git clone https://github.com/tu-usuario/python-expert-llama4.git
   cd python-expert-llama4
   ```

2. Configura tu API key de Groq en el archivo `.env`:
   ```bash
   # Editar el archivo .env
   GROQ_API_KEY=tu_api_key_aqui
   ```

3. **Sigue estos pasos para ejecutar el chat interactivo:**

   ```bash
   # Paso 1: Inicia los servicios en segundo plano
   docker-compose up -d
   
   # Paso 2: ConÃ©ctate al contenedor en modo interactivo 
   docker-compose exec app python -m interactive
   ```

   > **Nota:** Este es el flujo de trabajo estÃ¡ndar. El comando `docker-compose up` sin `-d` solo mostrarÃ¡ logs pero no permitirÃ¡ interacciÃ³n directa.

   Cuando veas el mensaje de bienvenida como este, ya puedes interactuar:

   ```
   â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
   â”‚                                                                 â”‚
   â”‚ ğŸ¤– Asistente Experto con LLaMA-4 Scout | Groq API               â”‚
   â”‚ --------------------------------                                â”‚
   â”‚ - Ventana de contexto: 131,072 tokens                           â”‚
   â”‚ - Respuestas hasta: 8,192 tokens                                â”‚
   â”‚ - Modo: Interactivo optimizado                                  â”‚
   â”‚                                                                 â”‚
   â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
   
   â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
   â”‚                     â„¹ï¸ INSTRUCCIONES                         â”‚
   â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
   Â¡Bienvenido al Chat! Puedes escribir directamente en esta terminal.
   
   Escribe /help para ver todos los comandos disponibles
   Para hacer una pregunta, solo escribe y presiona Enter
   ```
   
   **Nota importante:** Con `docker-compose up` normal (sin `-d`), verÃ¡s los logs pero NO podrÃ¡s interactuar con el chat. Esto se debe a que Docker no estÃ¡ conectando correctamente la entrada estÃ¡ndar (stdin) al contenedor en ese modo.

### InstalaciÃ³n local

1. Clona el repositorio:
   ```bash
   git clone https://github.com/tu-usuario/python-expert-llama4.git
   cd python-expert-llama4
   ```

2. Crea y activa un entorno virtual:
   ```bash
   python -m venv venv
   source venv/bin/activate  # En Windows: venv\Scripts\activate
   ```

3. Instala las dependencias (elige una opciÃ³n):
   ```bash
   # OpciÃ³n 1: Con uv (recomendado - mÃ¡s rÃ¡pido)
   uv pip install -r requirements.txt
   
   # OpciÃ³n 2: Con pip tradicional
   pip install -r requirements.txt
   ```

4. Crea un archivo `.env` en la raÃ­z del proyecto:
   ```
   GROQ_API_KEY=tu_api_key_aquÃ­
   DB_PATH=chat.db
   ```

### InstalaciÃ³n con Docker

1. Clona el repositorio:
   ```bash
   git clone https://github.com/tu-usuario/python-expert-llama4.git
   cd python-expert-llama4
   ```

2. Crea un archivo `.env` como se indicÃ³ anteriormente.

3. Construye y ejecuta el contenedor:
   ```bash
   make up
   ```

## ğŸ’» Uso

### Modo Interactivo (recomendado)

```bash
# Si usas Docker:
docker-compose up

# Si instalaste localmente:
python interactive.py
```

Una vez iniciado el modo interactivo, verÃ¡s la interfaz del asistente. Para usar el chat:

1. **Hacer preguntas sobre Python**: Simplemente escribe tu consulta tÃ©cnica y presiona Enter. Por ejemplo:
   ```
   Â¿CÃ³mo implementarÃ­a un patrÃ³n observer en Python?
   Explica las diferencias entre asyncio.gather() y asyncio.wait() con ejemplos
   Â¿CuÃ¡l es la mejor forma de manejar mÃºltiples excepciones en un bloque try/except?
   ```

2. **Comandos disponibles**:
   - `/help` - Mostrar lista de comandos disponibles
   - `/info` - Ver informaciÃ³n sobre el modelo y configuraciÃ³n
   - `/clear` - Reiniciar la conversaciÃ³n actual
   - `/temp [0.0-1.0]` - Ajustar temperatura de respuestas
   - `/tokens [100-8192]` - Cambiar lÃ­mite de tokens generados
   - `/export markdown [archivo]` - Exportar conversaciÃ³n a Markdown
   - `/export pdf [archivo]` - Exportar conversaciÃ³n a PDF
   - `/exit` o `/quit` - Salir del asistente

### Modo Comando

```bash
# Hacer una pregunta directa
python app.py ask "Â¿PodrÃ­as explicarme cÃ³mo aplicar el principio de responsabilidad Ãºnica (SRP) en un servicio de autenticaciÃ³n en Python con ejemplos?"

# Ver historial de conversaciones
python app.py history

# Ver estadÃ­sticas de uso
python app.py stats
```

### Ejemplos de ExportaciÃ³n

```bash
# En modo interactivo
/export markdown mi_conversacion.md
/export pdf reporte_chat.pdf
```

Los archivos exportados se guardarÃ¡n en el directorio actual, con formato profesional y toda la conversaciÃ³n estructurada.

## ğŸ” Sistema de SeparaciÃ³n de Contexto

La aplicaciÃ³n implementa un sistema avanzado de separaciÃ³n de contextos conversacionales que garantiza que cada sesiÃ³n de chat comienza limpia, sin contaminaciÃ³n de conversaciones anteriores.

### Arquitectura de tres capas

1. **SeparaciÃ³n en Base de Datos**:
   - Cada nueva sesiÃ³n genera un separador especial en la base de datos
   - La funciÃ³n `create_new_conversation()` marca el inicio claro de cada conversaciÃ³n
   - Los separadores contienen timestamps para identificaciÃ³n precisa

2. **Filtrado al Recuperar Mensajes**:
   - La funciÃ³n `get_all_messages()` filtra automÃ¡ticamente por conversaciÃ³n actual
   - ParÃ¡metro `current_conversation_only=True` asegura contexto limpio
   - RecuperaciÃ³n eficiente solo desde el Ãºltimo separador

3. **VerificaciÃ³n en Cliente API**:
   - Capa adicional de seguridad en `groq_client.py`
   - DetecciÃ³n y filtrado de separadores residuales
   - ProtecciÃ³n contra inconsistencias en capas anteriores

### Beneficios

- **Contexto Limpio**: Cada conversaciÃ³n parte de cero sin arrastrar contexto anterior
- **Respuestas Precisas**: El modelo responde exactamente a la pregunta actual
- **Eficiencia de Recursos**: EnvÃ­o al modelo solo del contexto relevante
- **Experiencia Mejorada**: Sin respuestas cruzadas o contaminadas


### Comandos bÃ¡sicos

- **Hacer una pregunta sobre Python**:
  ```bash
  python app.py ask "Muestra un ejemplo de decorador para medir el tiempo de ejecuciÃ³n de una funciÃ³n en Python"
  ```
  
  El asistente responderÃ¡ con cÃ³digo de Python que puedes usar directamente en tus proyectos:

- **Ver historial de chat**:
  ```bash
  python app.py history --limit 10  # Muestra las Ãºltimas 10 interacciones
  python app.py history --search "decoradores"  # Busca conversaciones sobre decoradores
  ```

- **Exportar conversaciÃ³n**:
  ```bash
  python app.py export --md  # Exportar a Markdown
  python app.py export --pdf  # Exportar a PDF
  python app.py export --md --pdf  # Exportar ambos formatos
  ```

- **Limpiar historial**:
  ```bash
  python app.py clear
  ```

### Opciones avanzadas

- **Cambiar modelo**:
  ```bash
  python app.py ask "Â¿CuÃ¡l es la capital de Francia?" --model meta-llama/llama-4-scout-17b-16e-instruct
  ```

- **Ajustar temperatura**:
  ```bash
  python app.py ask "Escribe un poema sobre el mar" --temperature 0.8
  ```

- **Limitar tokens**:
  ```bash
  python app.py ask "Resume la Guerra Civil EspaÃ±ola" --max-tokens 500
  ```

## ğŸ§ª Desarrollo

### ConfiguraciÃ³n del entorno de desarrollo

1. Instala las dependencias de desarrollo:
   ```bash
   make install-dev
   ```

2. Configura los hooks de pre-commit:
   ```bash
   make init-dev
   ```

### VerificaciÃ³n de calidad

- **Ejecutar linting**:
  ```bash
  make lint
  ```

- **Verificar tipos**:
  ```bash
  make type-check
  ```

- **Ejecutar tests**:
  ```bash
  make test
  ```

- **Ejecutar todas las verificaciones**:
  ```bash
  make quality
  ```

## ğŸ“Š Estructura del proyecto

```
python-expert-llama4/
â”œâ”€â”€ app.py              # CLI principal y punto de entrada
â”œâ”€â”€ groq_client.py      # Cliente para la API de Groq
â”œâ”€â”€ chat_db.py          # Manejo de base de datos para historial
â”œâ”€â”€ tests/              # Tests unitarios
â”œâ”€â”€ docs/               # DocumentaciÃ³n generada
â”œâ”€â”€ exports/            # Conversaciones exportadas
â”œâ”€â”€ .env                # Variables de entorno (no incluido en repo)
â”œâ”€â”€ makefile            # Comandos Ãºtiles
â”œâ”€â”€ pyproject.toml      # ConfiguraciÃ³n de herramientas
â””â”€â”€ README.md           # Este archivo
```

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Por favor, asegÃºrate de seguir estos pasos:

1. Haz fork del repositorio
2. Crea una rama para tu caracterÃ­stica (`git checkout -b feature/amazing-feature`)
3. Haz commit de tus cambios (`git commit -m 'Add some amazing feature'`)
4. Haz push a la rama (`git push origin feature/amazing-feature`)
5. Abre un Pull Request

## ğŸ“„ Licencia

Distribuido bajo la licencia MIT. Ver `LICENSE` para mÃ¡s informaciÃ³n.

## ğŸ™ Agradecimientos

- [Groq](https://groq.com) por proporcionar acceso a modelos Llama
- [Typer](https://typer.tiangolo.com/) para la interfaz CLI
- [Rich](https://rich.readthedocs.io/) para el formato en terminal
- [SQLAlchemy](https://www.sqlalchemy.org/) para el manejo de base de datos
